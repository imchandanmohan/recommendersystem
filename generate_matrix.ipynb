{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('AB_NYC_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NaN and reset index\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert integer columns to appropriate types (if needed)\n",
    "int_columns = ['host_id', 'price', 'minimum_nights', 'number_of_reviews', \n",
    "               'calculated_host_listings_count', 'availability_365']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in int_columns:\n",
    "    df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top 50 words from 'name' feature using Bag-of-Words\n",
    "vectorizer = CountVectorizer(max_features=600, stop_words='english')\n",
    "bow_matrix = vectorizer.fit_transform(df['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 168746 stored elements and shape (38821, 600)>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word frequencies\n",
    "word_counts = bow_matrix.sum(axis=0).A1\n",
    "vocab = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with words and their frequencies\n",
    "word_freq_df = pd.DataFrame({'word': vocab, 'count': word_counts})\n",
    "word_freq_df.sort_values(by='count', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>bth</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>row</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>convenience</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>rest</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>residence</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>cozy</td>\n",
       "      <td>4262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>apartment</td>\n",
       "      <td>5376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>private</td>\n",
       "      <td>6178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>bedroom</td>\n",
       "      <td>6444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>room</td>\n",
       "      <td>8278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  count\n",
       "111          bth     23\n",
       "462          row     24\n",
       "157  convenience     24\n",
       "444         rest     24\n",
       "443    residence     24\n",
       "..           ...    ...\n",
       "166         cozy   4262\n",
       "49     apartment   5376\n",
       "425      private   6178\n",
       "83       bedroom   6444\n",
       "459         room   8278\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 50 words\n",
    "top_50_words = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of words into a DataFrame\n",
    "top_50_df = pd.DataFrame(top_50_words, columns=['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame as a CSV file\n",
    "top_50_df.to_csv('top_50_words.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '10min', '12', '15', '15min', '15mins', '1b', '1ba', '1bd',\n",
       "       '1bdr', '1bdrm', '1bedroom', '1br', '1st', '20', '20min', '20mins',\n",
       "       '25', '2b', '2ba', '2bath', '2bd', '2bdrm', '2bed', '2bedroom',\n",
       "       '2br', '2nd', '30', '3bd', '3br', '3rd', '45', '4br', '5min',\n",
       "       '5th', 'abode', 'ac', 'access', 'adorable', 'affordable', 'air',\n",
       "       'airbnb', 'airport', 'airports', 'airy', 'alcove', 'amazing',\n",
       "       'amenities', 'apart', 'apartment', 'apple', 'apt', 'area', 'art',\n",
       "       'artist', 'artistic', 'artists', 'artsy', 'astoria', 'authentic',\n",
       "       'available', 'ave', 'avenue', 'away', 'awesome', 'backyard',\n",
       "       'balcony', 'barclays', 'basement', 'bath', 'bathroom', 'baths',\n",
       "       'bay', 'bd', 'bdr', 'bdrm', 'beach', 'beautiful', 'beautifully',\n",
       "       'beauty', 'bed', 'bedford', 'bedrm', 'bedroom', 'bedrooms', 'beds',\n",
       "       'bedstuy', 'best', 'big', 'bk', 'bklyn', 'bldg', 'block', 'blocks',\n",
       "       'blue', 'blueground', 'boerum', 'bohemian', 'boho', 'boutique',\n",
       "       'box', 'br', 'brand', 'breakfast', 'brick', 'bridge', 'bright',\n",
       "       'broadway', 'bronx', 'brooklyn', 'brownstone', 'bth', 'budget',\n",
       "       'building', 'bungalow', 'bunk', 'burg', 'bus', 'bushwick', 'cabin',\n",
       "       'calm', 'carroll', 'casa', 'cat', 'ceiling', 'ceilings', 'center',\n",
       "       'central', 'centrally', 'century', 'charm', 'charmer', 'charming',\n",
       "       'cheap', 'cheerful', 'chelsea', 'chic', 'chill', 'chinatown',\n",
       "       'circle', 'city', 'classic', 'classy', 'clean', 'cleaning',\n",
       "       'clinton', 'close', 'closet', 'cobble', 'colorful', 'columbia',\n",
       "       'columbus', 'comfort', 'comfortable', 'comfy', 'condo',\n",
       "       'contemporary', 'convenience', 'convenient', 'cool', 'corner',\n",
       "       'cosy', 'cottage', 'couch', 'couple', 'couples', 'cozy', 'crash',\n",
       "       'creative', 'crown', 'cute', 'day', 'days', 'deal', 'deck',\n",
       "       'delightful', 'deluxe', 'den', 'design', 'designed', 'designer',\n",
       "       'distance', 'district', 'ditmas', 'doorman', 'double', 'downtown',\n",
       "       'dream', 'dreamy', 'drenched', 'dryer', 'dumbo', 'duplex', 'east',\n",
       "       'easy', 'eclectic', 'elegant', 'elevator', 'empire', 'en', 'end',\n",
       "       'enjoy', 'ensuite', 'entire', 'entrance', 'entry', 'escape',\n",
       "       'excellent', 'exchange', 'exclusive', 'experience', 'exposed',\n",
       "       'express', 'extra', 'fabulous', 'factory', 'families', 'family',\n",
       "       'fantastic', 'fee', 'feel', 'female', 'females', 'ferry', 'fidi',\n",
       "       'filled', 'financial', 'finest', 'fl', 'flat', 'flatbush',\n",
       "       'flatiron', 'floor', 'flushing', 'forest', 'fort', 'free', 'fresh',\n",
       "       'friendly', 'ft', 'fully', 'fun', 'funky', 'furnished', 'garden',\n",
       "       'gardens', 'gem', 'getaway', 'good', 'gorgeous', 'gowanus',\n",
       "       'gramercy', 'grand', 'great', 'green', 'greene', 'greenpoint',\n",
       "       'greenwich', 'ground', 'groups', 'guest', 'guests', 'gym',\n",
       "       'hamilton', 'happy', 'harlem', 'haven', 'heart', 'heaven',\n",
       "       'heights', 'hell', 'hells', 'hidden', 'hideaway', 'high',\n",
       "       'highline', 'hill', 'hills', 'hip', 'historic', 'historical', 'hk',\n",
       "       'holiday', 'home', 'homey', 'hook', 'hostel', 'hotel', 'house',\n",
       "       'hudson', 'huge', 'ideal', 'ii', 'immaculate', 'incredible',\n",
       "       'industrial', 'inn', 'inviting', 'inwood', 'island', 'italy',\n",
       "       'jackson', 'jewel', 'jfk', 'just', 'kind', 'king', 'kitchen', 'la',\n",
       "       'laguardia', 'landmark', 'large', 'laundry', 'lefferts', 'les',\n",
       "       'level', 'lg', 'lga', 'lic', 'light', 'like', 'lincoln', 'line',\n",
       "       'lined', 'lit', 'little', 'live', 'lively', 'living', 'local',\n",
       "       'located', 'location', 'loft', 'lofted', 'long', 'lots', 'lounge',\n",
       "       'love', 'lovely', 'lovers', 'lower', 'lux', 'luxe', 'luxurious',\n",
       "       'luxury', 'madison', 'mall', 'manhattan', 'marks', 'massive',\n",
       "       'master', 'meatpacking', 'medical', 'metro', 'mi', 'mid', 'middle',\n",
       "       'midtown', 'min', 'mini', 'minimal', 'minimalist', 'mins',\n",
       "       'minute', 'minutes', 'modern', 'month', 'monthly', 'morningside',\n",
       "       'murray', 'museum', 'nash', 'natural', 'near', 'nearby', 'neat',\n",
       "       'neighborhood', 'nest', 'new', 'newly', 'nice', 'night', 'noho',\n",
       "       'nolita', 'nook', 'north', 'nr', 'ny', 'nyc', 'oasis', 'ocean',\n",
       "       'office', 'old', 'open', 'outdoor', 'overlooking', 'pad', 'palace',\n",
       "       'paradise', 'park', 'parking', 'parkside', 'parlor', 'patio',\n",
       "       'peaceful', 'penn', 'penthouse', 'people', 'perfect', 'person',\n",
       "       'pied', 'pk', 'place', 'plant', 'pleasant', 'plus', 'pool', 'pre',\n",
       "       'presidential', 'pretty', 'prewar', 'price', 'prime', 'priv',\n",
       "       'privacy', 'private', 'professionals', 'prospect', 'pvt', 'quaint',\n",
       "       'queen', 'queens', 'quick', 'quiet', 'quite', 'railroad', 'rare',\n",
       "       'real', 'red', 'relaxing', 'renovated', 'rent', 'rental',\n",
       "       'residence', 'rest', 'retreat', 'ride', 'ridge', 'ridgewood',\n",
       "       'right', 'rise', 'river', 'riverside', 'rm', 'rockaway',\n",
       "       'romantic', 'roof', 'roofdeck', 'rooftop', 'room', 'rooms',\n",
       "       'roomy', 'row', 'rustic', 'safe', 'sanctuary', 'separate',\n",
       "       'serene', 'serenity', 'service', 'serviced', 'share', 'shared',\n",
       "       'short', 'simple', 'single', 'size', 'sized', 'sky', 'skylight',\n",
       "       'skyline', 'sleek', 'sleep', 'sleeps', 'slope', 'small', 'sofa',\n",
       "       'soho', 'solo', 'sonder', 'south', 'space', 'spacious', 'special',\n",
       "       'spectacular', 'spot', 'sq', 'square', 'st', 'stadium', 'star',\n",
       "       'state', 'staten', 'station', 'stay', 'steps', 'stock', 'stop',\n",
       "       'stops', 'story', 'street', 'studio', 'stunning', 'stuy',\n",
       "       'stuyvesant', 'style', 'stylish', 'sublet', 'subway', 'subways',\n",
       "       'sugar', 'suite', 'summer', 'sun', 'sunlight', 'sunlit', 'sunny',\n",
       "       'sunnyside', 'sunset', 'super', 'superhost', 'sweet', 'term',\n",
       "       'terrace', 'terre', 'theater', 'time', 'times', 'tower', 'town',\n",
       "       'townhome', 'townhouse', 'train', 'trains', 'tranquil', 'traveler',\n",
       "       'travelers', 'tree', 'trendy', 'tribeca', 'triplex', 'true', 'tv',\n",
       "       'twin', 'ues', 'union', 'unique', 'unit', 'university', 'upper',\n",
       "       'upscale', 'uptown', 'urban', 'uws', 'vacation', 'value', 'vibes',\n",
       "       'vibrant', 'victorian', 'view', 'views', 'village', 'vintage',\n",
       "       'walk', 'walking', 'wall', 'war', 'warm', 'washer', 'washington',\n",
       "       'water', 'waterfront', 'wburg', 'welcome', 'welcoming', 'west',\n",
       "       'wifi', 'williamsburg', 'window', 'windows', 'women', 'wonderful',\n",
       "       'woodside', 'world', 'wyndham', 'xl', 'yankee', 'yard', 'york',\n",
       "       'zen'], dtype=object)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_50_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 168746 stored elements and shape (38821, 600)>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the top 50 features\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=top_50_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the original dataset with the Bag-of-Words features\n",
    "processed_df = pd.concat([df.reset_index(drop=True), bow_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original 'name' column (optional)\n",
    "processed_df.drop(columns=['name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by frequency to get the top 50 words\n",
    "top_50_df = word_freq_df.sort_values(by='count', ascending=False).head(600)\n",
    "\n",
    "# Save the top 50 words and their frequencies as a CSV file\n",
    "top_50_df.to_csv('top_50_words_with_frequencies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>...</th>\n",
       "      <th>women</th>\n",
       "      <th>wonderful</th>\n",
       "      <th>woodside</th>\n",
       "      <th>world</th>\n",
       "      <th>wyndham</th>\n",
       "      <th>xl</th>\n",
       "      <th>yankee</th>\n",
       "      <th>yard</th>\n",
       "      <th>york</th>\n",
       "      <th>zen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3831</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5022</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5099</td>\n",
       "      <td>7322</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Murray Hill</td>\n",
       "      <td>40.74767</td>\n",
       "      <td>-73.97500</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 615 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  host_id    host_name neighbourhood_group neighbourhood  latitude  \\\n",
       "0  2539     2787         John            Brooklyn    Kensington  40.64749   \n",
       "1  2595     2845     Jennifer           Manhattan       Midtown  40.75362   \n",
       "2  3831     4869  LisaRoxanne            Brooklyn  Clinton Hill  40.68514   \n",
       "3  5022     7192        Laura           Manhattan   East Harlem  40.79851   \n",
       "4  5099     7322        Chris           Manhattan   Murray Hill  40.74767   \n",
       "\n",
       "   longitude        room_type  price  minimum_nights  ...  women wonderful  \\\n",
       "0  -73.97237     Private room    149               1  ...      0         0   \n",
       "1  -73.98377  Entire home/apt    225               1  ...      0         0   \n",
       "2  -73.95976  Entire home/apt     89               1  ...      0         0   \n",
       "3  -73.94399  Entire home/apt     80              10  ...      0         0   \n",
       "4  -73.97500  Entire home/apt    200               3  ...      0         0   \n",
       "\n",
       "   woodside  world  wyndham  xl  yankee  yard  york  zen  \n",
       "0         0      0        0   0       0     0     0    0  \n",
       "1         0      0        0   0       0     0     0    0  \n",
       "2         0      0        0   0       0     0     0    0  \n",
       "3         0      0        0   0       0     0     0    0  \n",
       "4         0      0        0   0       0     0     0    0  \n",
       "\n",
       "[5 rows x 615 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the resulting dataset\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(200893891)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.memory_usage(deep=True).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38821, 615)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>10</th>\n",
       "      <th>10min</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>women</th>\n",
       "      <th>wonderful</th>\n",
       "      <th>woodside</th>\n",
       "      <th>world</th>\n",
       "      <th>wyndham</th>\n",
       "      <th>xl</th>\n",
       "      <th>yankee</th>\n",
       "      <th>yard</th>\n",
       "      <th>york</th>\n",
       "      <th>zen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Murray Hill</td>\n",
       "      <td>40.74767</td>\n",
       "      <td>-73.97500</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>200</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 607 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  neighbourhood_group neighbourhood  latitude  longitude        room_type  \\\n",
       "0            Brooklyn    Kensington  40.64749  -73.97237     Private room   \n",
       "1           Manhattan       Midtown  40.75362  -73.98377  Entire home/apt   \n",
       "2            Brooklyn  Clinton Hill  40.68514  -73.95976  Entire home/apt   \n",
       "3           Manhattan   East Harlem  40.79851  -73.94399  Entire home/apt   \n",
       "4           Manhattan   Murray Hill  40.74767  -73.97500  Entire home/apt   \n",
       "\n",
       "   price  number_of_reviews  10  10min  12  ...  women  wonderful  woodside  \\\n",
       "0    149                  9   0      0   0  ...      0          0         0   \n",
       "1    225                 45   0      0   0  ...      0          0         0   \n",
       "2     89                270   0      0   0  ...      0          0         0   \n",
       "3     80                  9   0      0   0  ...      0          0         0   \n",
       "4    200                 74   0      0   0  ...      0          0         0   \n",
       "\n",
       "   world  wyndham  xl  yankee  yard  york  zen  \n",
       "0      0        0   0       0     0     0    0  \n",
       "1      0        0   0       0     0     0    0  \n",
       "2      0        0   0       0     0     0    0  \n",
       "3      0        0   0       0     0     0    0  \n",
       "4      0        0   0       0     0     0    0  \n",
       "\n",
       "[5 rows x 607 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unwanted columns\n",
    "processed_df = processed_df.drop(columns=['host_name', 'host_id', 'id','minimum_nights','last_review','reviews_per_month','calculated_host_listings_count','availability_365'])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "processed_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38821, 607)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# # Use only latitude and longitude to create geographical clusters\n",
    "# geo_data = processed_df[['latitude', 'longitude']].values\n",
    "\n",
    "# # Fit a k-means clustering model (e.g., 10 clusters)\n",
    "# kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "# processed_df['geo_cluster'] = kmeans.fit_predict(geo_data)\n",
    "\n",
    "# # Now, use 'geo_cluster' as an additional feature for similarity computation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_df['geo_cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Normalize the 'price' column\n",
    "# scaler = StandardScaler()\n",
    "# processed_df['price_scaled'] = scaler.fit_transform(processed_df[['price']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_df['price_scaled'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Indices: [    0  3730 24384]\n",
      "Recommended Distances: [0.99999994 0.9999118  0.999911  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "\n",
    "# 1. Prepare the Data\n",
    "# Keep only numeric and one-hot encoded columns\n",
    "data = processed_df.select_dtypes(include=[np.number]).values\n",
    "\n",
    "# Normalize the data for cosine similarity\n",
    "data_normalized = data / np.linalg.norm(data, axis=1, keepdims=True)\n",
    "\n",
    "# 2. Create and Train the FAISS Index\n",
    "d = data_normalized.shape[1]  # Dimensionality of the data\n",
    "index = faiss.IndexFlatIP(d)  # Inner Product (cosine similarity)\n",
    "index.add(data_normalized)    # Add data to the index\n",
    "\n",
    "# Save the model\n",
    "faiss.write_index(index, 'airbnb_recommender.index')\n",
    "\n",
    "# 3. Query the Model\n",
    "def recommend(new_data, k=3):\n",
    "    \"\"\"\n",
    "    Given a new listing, recommend k similar listings.\n",
    "    \n",
    "    Args:\n",
    "        new_data (numpy array): The feature vector for the new listing.\n",
    "        k (int): Number of recommendations.\n",
    "    \n",
    "    Returns:\n",
    "        indices (list): Indices of the top k similar listings.\n",
    "        distances (list): Similarity scores of the top k listings.\n",
    "    \"\"\"\n",
    "    # Normalize the new data\n",
    "    new_data_normalized = new_data / np.linalg.norm(new_data, axis=1, keepdims=True)\n",
    "    \n",
    "    # Perform a search\n",
    "    distances, indices = index.search(new_data_normalized, k)\n",
    "    return indices, distances\n",
    "\n",
    "# Example: Recommend for the first listing in the dataset\n",
    "new_listing = data_normalized[0].reshape(1, -1)\n",
    "recommended_indices, recommended_distances = recommend(new_listing)\n",
    "\n",
    "# Output the recommendations\n",
    "print(\"Recommended Indices:\", recommended_indices[0])\n",
    "print(\"Recommended Distances:\", recommended_distances[0])\n",
    "\n",
    "# Save index for future use\n",
    "faiss.write_index(index, 'airbnb_recommender.index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 604)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_listing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 604)\n"
     ]
    }
   ],
   "source": [
    "# Load the new listing from the CSV file\n",
    "loaded_new_listing = pd.read_csv('new_listing.csv', header=None)\n",
    "\n",
    "# Convert the loaded DataFrame to a 1D numpy array and reshape it to (1, 604)\n",
    "loaded_new_listing = loaded_new_listing.values\n",
    "\n",
    "# Verify the shape\n",
    "print(loaded_new_listing.shape)  # Should be (1, 604)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13932279, -0.25283771,  0.44449031,  0.84795075,  0.        ,\n",
       "         0.        ,  0.00341916,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.00341916,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.00341916,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.00341916,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.00341916,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.00341916,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_new_listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Indices: [  41 2919  637]\n",
      "Recommended Distances: [0.9999299 0.9998989 0.9998839]\n"
     ]
    }
   ],
   "source": [
    "# Now you can pass loaded_new_listing into your recommendation function\n",
    "recommended_indices, recommended_distances = recommend(loaded_new_listing)\n",
    "\n",
    "# Output the recommendations\n",
    "print(\"Recommended Indices:\", recommended_indices[0])\n",
    "print(\"Recommended Distances:\", recommended_distances[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38821, 604)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38821, 607)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded index has 38821 vectors with 604 dimensions\n"
     ]
    }
   ],
   "source": [
    "index = faiss.read_index('airbnb_recommender.index')\n",
    "print(f\"Loaded index has {index.ntotal} vectors with {index.d} dimensions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors before saving: 38821\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of vectors before saving: {index.ntotal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
